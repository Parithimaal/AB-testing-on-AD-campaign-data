---
title: "A/B Testing on Ad campaign"
author: "Balaji Adithya Dhandapani Shanmugasundaram"
date: "2023-08-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

```

# Data Preprocessing

Load necessary libraries and reading csv

```{r}
library(readxl)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(ggpubr)
library(car)
library(DescTools)
library(lmtest)
```

View dataset structure

```{r}
data <- read_csv("AB-testing-on-AD-campaign-data/Data Files/marketing_AB.csv")
glimpse(data)
```

Dropping, renaming and converting columns

```{r}
#Dropping
data <- data %>% select(-c(`...1`, `user id`))

#Renaming
colnames(data) <- c("test_group", "converted", "total_ads", "most_ads_day", "most_ads_hour")

#Converting data type
data$converted <- ifelse(data$converted == 'TRUE', 1, 0)
data$test_group <- as.factor(data$test_group)
data$most_ads_hour <- as.factor(data$most_ads_hour)
data$most_ads_day <- as.factor(data$most_ads_day)
#data$converted <- as.factor(data$converted) # mutating converted to 0,1
```

Checking empty values

```{r}
colSums(is.na(data))
```

# EDA

```{r}
ulst <- lapply(data, unique)
ulst
```

```{r}
summary(data)
```

**Interpretation:**

1.  The test_group is heavily skewed, only 4.1% of the records are psa

2.  The Conversion rate was quite low, at about 2.4%

3.  Participants saw ads with a median of 13

4.  Friday and Monday were the days, most number of ads were shown and Tuesday and Wednesday were the least.

5.  Most ads were displayed from 11am to 3pm

Comparing conversion rates between the two classes of feature:converted

```{r}
data$converted <- as.numeric(data$converted) # mutating converted to 0,1
# Conversion rates by test group
conversion_rates <- data %>%
  group_by(test_group) %>%
  summarise(
    total_count = n(),
    converted_count = sum(converted),
    conversion_rate = (converted_count / total_count) * 100
  )

print(conversion_rates)
```

**Observation:** The conversion rates are 2.55% and 1.79% for ad and psa classes respectively.

Comparing Distribution of Total Ads by Test Group

```{r}
ggplot(data, aes(x = test_group, y = total_ads, fill = test_group)) +
  geom_boxplot() +
  labs(title = "Distribution of Total Ads by Test Group", x = "Test Group", y = "Total Ads") +
  theme_minimal()
```

**Observation:** Both distributions(for ad and psa) are highly right-skewed. The bulk of the data for both groups appears to be concentrated in the lower range (close to 0).

Comparing Most Ads Served by Day by Test Group

```{r}
ggplot(data, aes(x = most_ads_day, fill = test_group)) +
  geom_bar(position = "dodge") +
  labs(title = "Most Ads Served by Day", x = "Day of the Week", y = "Count") +
  theme_minimal()
```

**Observation:** The trend of most ads served by day differs between the two groups.

Comparing Most Ads Served by Test Group

```{r}
data$most_ads_hour <- as.numeric(data$most_ads_hour)
ggplot(data, aes(x = most_ads_hour, fill = test_group)) +
  geom_histogram(binwidth = 1, alpha = 0.7, position = "dodge") +
  labs(title = "Distribution of Most Ads Served by Hour", x = "Hour of the Day", y = "Count") +
  theme_minimal()
```

**Observation:** The trend of most ads served by hours is similar among the two groups.

# Tests

## Chi-squared test

### Hypothesis

-   **Null Hypothesis (H₀):** There is no association between the test group (ad vs. PSA) and conversion rates. The proportion of conversions is the **same** for both groups.

-   **Alternative Hypothesis (H₁):** There is a significant association between the test group and conversion rates. The conversion rate **differs** between the groups.

```{r}
# Create a contingency table of conversions by test group
conversion_table <- table(data$test_group, data$converted)
print(conversion_table)

# Perform the Chi-Squared test
chi_test_result <- chisq.test(conversion_table, correct = FALSE)
print(chi_test_result)

```

### **Interpretation**

X-squared = 54.318, df = 1, p-value = 1.705e-13. As p\<0.05 (Significance level), we can conclude that the variables test_group and converted are dependent, thereby there exists significant difference between the conversion rates between the two groups.

But we have to test for interaction between other features. Let us fit a logistic model to ascertain if there exists an interaction.

## Anova

```{r}
library(lmerTest)

# Convert categorical variables to factors
data$test_group <- as.factor(data$test_group)
data$most_ads_day <- as.factor(data$most_ads_day)
data$most_ads_hour <- as.factor(data$most_ads_hour)

# Factorial ANOVA Model
anova_model <- aov(converted ~ test_group * most_ads_day * most_ads_hour * total_ads, data = data)

# Print ANOVA summary
summary(anova_model)

```

### Interpretation

### Main Factors

-   All the main factors were highly significant (p\<0.05)

-   The total_ads was the strongest predictor due to the highest F value

### Two Factor interactions

-   No significant interaction between test_group and most_ads_day or most_ads_hour. The effect of ads is mostly independent of the day or hour of exposure.

-   Strong interaction between most_ads_day and most_ads_hour. This suggests that certain hours on specific days are more effective for conversions. Strong interaction between total_ads and all other variables. This means that the effect of total ads depends on the day and hour, meaning some times are better for ad exposure.

### Three factor interactions

-   All three-way interactions: (test_group \* most_ads_day \* total_ads, test_group \* most_ads_hour \* total_ads, most_ads_day \* most_ads_hour \* total_ads) were significant

### Four-Way Interaction Effect

-   The four-way interaction effect was significant

In conclusion all four factors together significantly influence conversion. This means conversions are not just driven by seeing an ad, but also by when and how many ads were seen. Now let us explore the interactions with Tukey test.

## Tukey Test

```{r}
# Perform Tukey HSD post-hoc test for most_ads_day
tukey_day <- TukeyHSD(anova_model, "most_ads_day")
print(tukey_day)

# Perform Tukey HSD post-hoc test for most_ads_hour
tukey_hour <- TukeyHSD(anova_model, "most_ads_hour")
print(tukey_hour)

# Perform Tukey HSD post-hoc test for interaction (most_ads_day * most_ads_hour)
tukey_interaction <- TukeyHSD(anova_model, "most_ads_day:most_ads_hour")
print(tukey_interaction)
```

```{r}
# Visualizing Tukey results for most_ads_day
#dev.new(width=20, height=10, unit="in") 
#plot(tukey_day, las = 1, col = "blue")
#title("Tukey HSD: Most Ads Day")

png("tukey_Day_plot.png", width = 800, height = 600)
par(mar = c(5, 10, 4, 2))
plot(tukey_day, las = 1, col = "blue")
dev.off()

```

```{r}
# Visualizing Tukey results for most_ads_hour
#plot(tukey_hour, las = 1, col = "red")
#title("Tukey HSD: Most Ads Hour")
png("tukey_hour_plot.png", width = 800, height = 600)
par(mar = c(5, 6, 4, 2))
plot(tukey_hour, las = 1, col = "red")
dev.off()

```

```{r}
# Visualizing Tukey results for most_ads_day × most_ads_hour interaction
#plot(tukey_interaction, las = 1, col = "green", main = "Tukey HSD: Interaction (Day * Hour)")

png("tukey_interaction_plot.png", width = 800, height = 600)
par(mar = c(5, 12, 4, 2))
plot(tukey_interaction, las = 1, col = "green")
dev.off()
```

### Interpretation

-   The largest differences appear between Saturday-Monday and Tuesday-Saturday pairs (farthest from 0)

-   The largest differences appear to be in the comparisons of the hours 5-1, 13-1, 21-1

-   Due to the high number of levels of factors, interpretability from the plots is lost

## LogReg: Base model

```{r}
logit_model_no_interaction <- glm(converted ~ test_group + total_ads + most_ads_day + most_ads_hour,
                                   data = data, family = binomial())

summary(logit_model_no_interaction)  # Check significance of coefficients
exp(coef(logit_model_no_interaction))
```

### Checking Assumptions

```{r}
data$logit <- log(data$converted / (1 - data$converted + 1e-5))
ggplot(data, aes(x = total_ads, y = logit)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "blue") +
  labs(title = "Linearity Check: Total Ads vs Logit")

```

```{r}
ggplot(data, aes(x = most_ads_hour, y = logit)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "blue") +
  labs(title = "Linearity Check: Most Ads Hour vs Logit")
```

### Multicollinearity

```{r}
library(car)
vif_values <- vif(logit_model_no_interaction)
print(vif_values)
```

### Outliers

```{r}
influence <- influence.measures(logit_model_no_interaction)
summary(influence)

# Cook’s distance plot
plot(logit_model_no_interaction, which = 4)

```

### Auto-correlation

```{r}
library(lmtest)
dwtest(logit_model_no_interaction)
```

### **Interpretation**

1.  Linearity Assumption is violated. The shape of graph is irregular so transformations might not help

2.  Cook's distance plot shows us that there exist a huge number of influential outliers

3.  The data does not exhibit multi-collinearity as VIF values \< 5

4.  There is significant auto-correlation

Thus log model may not be suitable for this case.

## Two proportion z-test

### Assumption

Let us assume that the two groups are independent (Ruling out network effect).

### Hypothesis

-   **Null Hypothesis (H₀):** The proportion of converted users is the **same** in both the ad and PSA groups.

-   **Alternative Hypothesis (H₁):** The proportion of converted users is **different** between the ad and PSA groups.

```{r}
# Summarize the conversion counts for each group
conversion_summary <- data %>%
  group_by(test_group) %>%
  summarise(conversion_count = sum(converted), total_users = n())

# Perform a two-proportion Z-test
prop_test <- prop.test(conversion_summary$conversion_count, conversion_summary$total_users)

print(prop_test)
```

### Interpretation

p\<\<0.05. Therefore, we can reject the null hypothesis and conclude that the proportion of converts between the two groups is different.

## Random Forest model

Let us fit a Random Forest model and assess feature importance

```{r}
library(randomForest)

data$converted <- as.factor(data$converted)  # Convert response to factor

# Train random forest model
rf_model <- randomForest(converted ~ test_group + most_ads_day + most_ads_hour + total_ads, 
                         data = data, ntree = 500, importance = TRUE)

print(rf_model)

# Check variable importance
importance(rf_model)
varImpPlot(rf_model)

```

### Interpretation

-   We find that total_ads feature has the most predictive power in predicting conversion

-   most_ads_day and most_ads_hour had similar predictive power

-   test_group was least relevant for branching in the random forest.

# Findings

## **1. Impact of Ads on Conversion Rates**

The A/B test results indicate that ads significantly improve conversion rates compared to psa. The test_group factor was statistically significant (p \< 0.05), confirming that users who were exposed to advertisements were more likely to convert. The conversion rates are 2.55% and 1.79% for ad and psa classes respectively.

## 2. Interaction effects

All the main effects were significant Most of interactions effects except for (test_group \* most_ads_day) and (test_group \* most_ads_hour ) were statistically significant.

## 3. Most Significant factor

The total ads views by the user was the most significant predictor of conversion
